{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85eb1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a4984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_train = pd.read_csv(\"C:/Users/user/.jupyter/주피터 파일/data/planets_train.csv\")\n",
    "planets_train.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "planets_test = pd.read_csv(\"C:/Users/user/.jupyter/주피터 파일/data/planets_test.csv\")\n",
    "planets_test.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4361ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = planets_train.iloc[:, 1:6]\n",
    "train_y = planets_train.iloc[:, 0]\n",
    "\n",
    "test_x = planets_test.iloc[:, 1:6]\n",
    "test_y = planets_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04041fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.where((train_y == 'Radial Velocity') | (train_y == 'Transit'), 'Others')\n",
    "test_y = test_y.where((test_y == 'Radial Velocity') | (test_y == 'Transit'), 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d639a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[['orbital_period', 'distance', 'mass']] = np.log(train_x[['orbital_period', 'distance', 'mass']])\n",
    "test_x[['orbital_period', 'distance', 'mass']] = np.log(test_x[['orbital_period', 'distance', 'mass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5560f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.interpolate()\n",
    "test_x = test_x.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fee7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "\n",
    "train_x = RobustScaler().fit_transform(train_x)\n",
    "test_x = RobustScaler().fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e510326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "x_train, y_train = SMOTE(random_state=0).fit_resample(train_x, train_y)\n",
    "x_test, y_test = SMOTE(random_state=0).fit_resample(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254682e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "y_test = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dcf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = pd.get_dummies(y_train).values\n",
    "y_test_oh = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838d9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train_oh = torch.from_numpy(y_train_oh).float()\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test_oh = torch.from_numpy(y_test_oh).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee3bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train_oh)\n",
    "test_dataset = TensorDataset(x_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e528a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed17ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "        def __init__(self,n_input = 5, n_output=3):\n",
    "            super(Net,self).__init__()\n",
    "            self.n_in = n_input\n",
    "            self.n_out = n_output\n",
    "            self.fc1 = nn.Linear(self.n_in,64)\n",
    "            self.fc2 = nn.Linear(64,256)\n",
    "            self.fc3 = nn.Linear(256,self.n_out)\n",
    "            self.relu = nn.ReLU()\n",
    "            #self.dropout = nn.Dropout(0.5)\n",
    "            self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        def forward(self,x):\n",
    "            out = self.relu(self.fc1(x))\n",
    "            out = self.relu(self.fc2(out))\n",
    "            out = self.dropout(out)\n",
    "            out = self.softmax(self.fc3(out))\n",
    "            \n",
    "            return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd8d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchNet(5,3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.001)\n",
    "Epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd8f5e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Loss : 0.033148665639959704, ACC : 0.5093724531377343\n",
      "Epoch 2/200\n",
      "Loss : 0.029471630377796675, ACC : 0.6405867970660146\n",
      "Epoch 3/200\n",
      "Loss : 0.02727115834351954, ACC : 0.7049714751426243\n",
      "Epoch 4/200\n",
      "Loss : 0.026248267635448054, ACC : 0.7408312958435208\n",
      "Epoch 5/200\n",
      "Loss : 0.025714555598898643, ACC : 0.7603911980440098\n",
      "Epoch 6/200\n",
      "Loss : 0.02543444442088369, ACC : 0.7571312143439283\n",
      "Epoch 7/200\n",
      "Loss : 0.0251165871806716, ACC : 0.7644661776691116\n",
      "Epoch 8/200\n",
      "Loss : 0.024870855835461482, ACC : 0.771801140994295\n",
      "Epoch 9/200\n",
      "Loss : 0.024706756475988013, ACC : 0.784841075794621\n",
      "Epoch 10/200\n",
      "Loss : 0.02463785030050985, ACC : 0.78239608801956\n",
      "Epoch 11/200\n",
      "Loss : 0.024494515605932732, ACC : 0.7889160554197229\n",
      "Epoch 12/200\n",
      "Loss : 0.024281995220697305, ACC : 0.8092909535452323\n",
      "Epoch 13/200\n",
      "Loss : 0.024341743314956005, ACC : 0.7954360228198859\n",
      "Epoch 14/200\n",
      "Loss : 0.02408148985911698, ACC : 0.8092909535452323\n",
      "Epoch 15/200\n",
      "Loss : 0.023896379643761248, ACC : 0.8060309698451508\n",
      "Epoch 16/200\n",
      "Loss : 0.02387077597553592, ACC : 0.7986960065199674\n",
      "Epoch 17/200\n",
      "Loss : 0.023588378204013043, ACC : 0.8215158924205379\n",
      "Epoch 18/200\n",
      "Loss : 0.023392602157670497, ACC : 0.8215158924205379\n",
      "Epoch 19/200\n",
      "Loss : 0.023428948069357153, ACC : 0.8288508557457213\n",
      "Epoch 20/200\n",
      "Loss : 0.02339739646966028, ACC : 0.8182559087204564\n",
      "Epoch 21/200\n",
      "Loss : 0.023161187682971783, ACC : 0.8329258353708231\n",
      "Epoch 22/200\n",
      "Loss : 0.023143887131216085, ACC : 0.8272208638956805\n",
      "Epoch 23/200\n",
      "Loss : 0.02299732251583121, ACC : 0.8321108394458028\n",
      "Epoch 24/200\n",
      "Loss : 0.023003214971749106, ACC : 0.8329258353708231\n",
      "Epoch 25/200\n",
      "Loss : 0.02289179246796761, ACC : 0.8402607986960066\n",
      "Epoch 26/200\n",
      "Loss : 0.022664054147383015, ACC : 0.8459657701711492\n",
      "Epoch 27/200\n",
      "Loss : 0.022787710905269383, ACC : 0.8492257538712307\n",
      "Epoch 28/200\n",
      "Loss : 0.022781995077296398, ACC : 0.8427057864710676\n",
      "Epoch 29/200\n",
      "Loss : 0.022810701101702604, ACC : 0.8451507742461287\n",
      "Epoch 30/200\n",
      "Loss : 0.02252730360435293, ACC : 0.8484107579462102\n",
      "Epoch 31/200\n",
      "Loss : 0.02266600016373974, ACC : 0.8484107579462102\n",
      "Epoch 32/200\n",
      "Loss : 0.022463375023932794, ACC : 0.8598207008964955\n",
      "Epoch 33/200\n",
      "Loss : 0.022448034235978378, ACC : 0.850040749796251\n",
      "Epoch 34/200\n",
      "Loss : 0.02247823756598027, ACC : 0.8516707416462918\n",
      "Epoch 35/200\n",
      "Loss : 0.022387450607986886, ACC : 0.8508557457212714\n",
      "Epoch 36/200\n",
      "Loss : 0.022519903787288027, ACC : 0.8524857375713122\n",
      "Epoch 37/200\n",
      "Loss : 0.022324726167692825, ACC : 0.8557457212713936\n",
      "Epoch 38/200\n",
      "Loss : 0.022238779087424183, ACC : 0.8516707416462918\n",
      "Epoch 39/200\n",
      "Loss : 0.022312238678858353, ACC : 0.850040749796251\n",
      "Epoch 40/200\n",
      "Loss : 0.022132239209604925, ACC : 0.863080684596577\n",
      "Epoch 41/200\n",
      "Loss : 0.022208783134951664, ACC : 0.8581907090464548\n",
      "Epoch 42/200\n",
      "Loss : 0.022350639517752253, ACC : 0.8508557457212714\n",
      "Epoch 43/200\n",
      "Loss : 0.02224413140964586, ACC : 0.8549307253463733\n",
      "Epoch 44/200\n",
      "Loss : 0.022390104739182154, ACC : 0.8581907090464548\n",
      "Epoch 45/200\n",
      "Loss : 0.022061241479452393, ACC : 0.8663406682966586\n",
      "Epoch 46/200\n",
      "Loss : 0.02210028801104259, ACC : 0.863080684596577\n",
      "Epoch 47/200\n",
      "Loss : 0.02215302549150773, ACC : 0.8533007334963325\n",
      "Epoch 48/200\n",
      "Loss : 0.02203623720952526, ACC : 0.8581907090464548\n",
      "Epoch 49/200\n",
      "Loss : 0.022001334682362005, ACC : 0.8638956805215974\n",
      "Epoch 50/200\n",
      "Loss : 0.02207068446795923, ACC : 0.8614506927465363\n",
      "Epoch 51/200\n",
      "Loss : 0.02176483477046068, ACC : 0.8663406682966586\n",
      "Epoch 52/200\n",
      "Loss : 0.022072603086581925, ACC : 0.8622656886715566\n",
      "Epoch 53/200\n",
      "Loss : 0.02207399765067501, ACC : 0.8647106764466178\n",
      "Epoch 54/200\n",
      "Loss : 0.021902970647850753, ACC : 0.8712306438467807\n",
      "Epoch 55/200\n",
      "Loss : 0.02194153465871026, ACC : 0.8647106764466178\n",
      "Epoch 56/200\n",
      "Loss : 0.021627474627848458, ACC : 0.882640586797066\n",
      "Epoch 57/200\n",
      "Loss : 0.021869323704431187, ACC : 0.8704156479217604\n",
      "Epoch 58/200\n",
      "Loss : 0.021874314804046058, ACC : 0.8704156479217604\n",
      "Epoch 59/200\n",
      "Loss : 0.021729451131315473, ACC : 0.8736756316218419\n",
      "Epoch 60/200\n",
      "Loss : 0.021853217431560414, ACC : 0.86960065199674\n",
      "Epoch 61/200\n",
      "Loss : 0.02186897268310833, ACC : 0.8753056234718827\n",
      "Epoch 62/200\n",
      "Loss : 0.021796028062203307, ACC : 0.86960065199674\n",
      "Epoch 63/200\n",
      "Loss : 0.021618088426488925, ACC : 0.8769356153219234\n",
      "Epoch 64/200\n",
      "Loss : 0.021736217448647274, ACC : 0.8687856560717196\n",
      "Epoch 65/200\n",
      "Loss : 0.021738390224972873, ACC : 0.8655256723716381\n",
      "Epoch 66/200\n",
      "Loss : 0.021560488042543843, ACC : 0.8777506112469438\n",
      "Epoch 67/200\n",
      "Loss : 0.02157719653121028, ACC : 0.8785656071719642\n",
      "Epoch 68/200\n",
      "Loss : 0.021598842635617184, ACC : 0.8728606356968215\n",
      "Epoch 69/200\n",
      "Loss : 0.021657485347893923, ACC : 0.8736756316218419\n",
      "Epoch 70/200\n",
      "Loss : 0.02168197804771989, ACC : 0.8687856560717196\n",
      "Epoch 71/200\n",
      "Loss : 0.021656330368240967, ACC : 0.8744906275468622\n",
      "Epoch 72/200\n",
      "Loss : 0.02172247457037928, ACC : 0.8736756316218419\n",
      "Epoch 73/200\n",
      "Loss : 0.021549368157266307, ACC : 0.8785656071719642\n",
      "Epoch 74/200\n",
      "Loss : 0.021717859266633995, ACC : 0.8671556642216789\n",
      "Epoch 75/200\n",
      "Loss : 0.021466307797466923, ACC : 0.882640586797066\n",
      "Epoch 76/200\n",
      "Loss : 0.021329247572602735, ACC : 0.882640586797066\n",
      "Epoch 77/200\n",
      "Loss : 0.021666708717330646, ACC : 0.8712306438467807\n",
      "Epoch 78/200\n",
      "Loss : 0.02139997618316924, ACC : 0.8810105949470253\n",
      "Epoch 79/200\n",
      "Loss : 0.021475493956506008, ACC : 0.8769356153219234\n",
      "Epoch 80/200\n",
      "Loss : 0.02141008366388136, ACC : 0.8850855745721271\n",
      "Epoch 81/200\n",
      "Loss : 0.021504308114522048, ACC : 0.8753056234718827\n",
      "Epoch 82/200\n",
      "Loss : 0.021374848380551266, ACC : 0.8875305623471883\n",
      "Epoch 83/200\n",
      "Loss : 0.02164051594924616, ACC : 0.8801955990220048\n",
      "Epoch 84/200\n",
      "Loss : 0.021366738456968574, ACC : 0.8859005704971475\n",
      "Epoch 85/200\n",
      "Loss : 0.021632893792768757, ACC : 0.8728606356968215\n",
      "Epoch 86/200\n",
      "Loss : 0.021313416102890476, ACC : 0.8859005704971475\n",
      "Epoch 87/200\n",
      "Loss : 0.021507877398042437, ACC : 0.8769356153219234\n",
      "Epoch 88/200\n",
      "Loss : 0.021423397748180785, ACC : 0.8777506112469438\n",
      "Epoch 89/200\n",
      "Loss : 0.021463849093725552, ACC : 0.8744906275468622\n",
      "Epoch 90/200\n",
      "Loss : 0.02159693863883481, ACC : 0.8785656071719642\n",
      "Epoch 91/200\n",
      "Loss : 0.021361121581449875, ACC : 0.8859005704971475\n",
      "Epoch 92/200\n",
      "Loss : 0.021325507004667125, ACC : 0.8859005704971475\n",
      "Epoch 93/200\n",
      "Loss : 0.021245760459091573, ACC : 0.8899755501222494\n",
      "Epoch 94/200\n",
      "Loss : 0.021267427451841795, ACC : 0.8875305623471883\n",
      "Epoch 95/200\n",
      "Loss : 0.021347828871269195, ACC : 0.8818255908720456\n",
      "Epoch 96/200\n",
      "Loss : 0.021192130949211588, ACC : 0.8850855745721271\n",
      "Epoch 97/200\n",
      "Loss : 0.02124106412800522, ACC : 0.8842705786471068\n",
      "Epoch 98/200\n",
      "Loss : 0.02130456877221105, ACC : 0.8875305623471883\n",
      "Epoch 99/200\n",
      "Loss : 0.02124504845804962, ACC : 0.8924205378973105\n",
      "Epoch 100/200\n",
      "Loss : 0.0210978614671889, ACC : 0.8916055419722901\n",
      "Epoch 101/200\n",
      "Loss : 0.021454983983665535, ACC : 0.8818255908720456\n",
      "Epoch 102/200\n",
      "Loss : 0.021416157848386134, ACC : 0.8810105949470253\n",
      "Epoch 103/200\n",
      "Loss : 0.02114029701103888, ACC : 0.8899755501222494\n",
      "Epoch 104/200\n",
      "Loss : 0.021205727317611084, ACC : 0.8875305623471883\n",
      "Epoch 105/200\n",
      "Loss : 0.021190429180739077, ACC : 0.8907905460472698\n",
      "Epoch 106/200\n",
      "Loss : 0.021255893054393217, ACC : 0.8875305623471883\n",
      "Epoch 107/200\n",
      "Loss : 0.0212428163685445, ACC : 0.8883455582722086\n",
      "Epoch 108/200\n",
      "Loss : 0.021237149798199715, ACC : 0.8850855745721271\n",
      "Epoch 109/200\n",
      "Loss : 0.02106756316809122, ACC : 0.8916055419722901\n",
      "Epoch 110/200\n",
      "Loss : 0.021189951954960533, ACC : 0.8859005704971475\n",
      "Epoch 111/200\n",
      "Loss : 0.021356708894634792, ACC : 0.8801955990220048\n",
      "Epoch 112/200\n",
      "Loss : 0.02127167852117263, ACC : 0.8859005704971475\n",
      "Epoch 113/200\n",
      "Loss : 0.0212506063604316, ACC : 0.8859005704971475\n",
      "Epoch 114/200\n",
      "Loss : 0.02118417443350844, ACC : 0.8875305623471883\n",
      "Epoch 115/200\n",
      "Loss : 0.021209842272667548, ACC : 0.8859005704971475\n",
      "Epoch 116/200\n",
      "Loss : 0.021075610475221492, ACC : 0.8907905460472698\n",
      "Epoch 117/200\n",
      "Loss : 0.021194664802411365, ACC : 0.8899755501222494\n",
      "Epoch 118/200\n",
      "Loss : 0.02105513173774091, ACC : 0.8916055419722901\n",
      "Epoch 119/200\n",
      "Loss : 0.021167670067676024, ACC : 0.8916055419722901\n",
      "Epoch 120/200\n",
      "Loss : 0.021148902085513337, ACC : 0.8899755501222494\n",
      "Epoch 121/200\n",
      "Loss : 0.021115450035194702, ACC : 0.8850855745721271\n",
      "Epoch 122/200\n",
      "Loss : 0.021200090719610088, ACC : 0.8891605541972291\n",
      "Epoch 123/200\n",
      "Loss : 0.02105798022768414, ACC : 0.8940505297473512\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.0210569748668624, ACC : 0.8883455582722086\n",
      "Epoch 125/200\n",
      "Loss : 0.021130997617747983, ACC : 0.8883455582722086\n",
      "Epoch 126/200\n",
      "Loss : 0.021023186319906146, ACC : 0.8932355338223309\n",
      "Epoch 127/200\n",
      "Loss : 0.02099051971987388, ACC : 0.8964955175224124\n",
      "Epoch 128/200\n",
      "Loss : 0.021081229633884695, ACC : 0.8891605541972291\n",
      "Epoch 129/200\n",
      "Loss : 0.021097897123105173, ACC : 0.8891605541972291\n",
      "Epoch 130/200\n",
      "Loss : 0.02108121875251515, ACC : 0.8907905460472698\n",
      "Epoch 131/200\n",
      "Loss : 0.02095030115791327, ACC : 0.895680521597392\n",
      "Epoch 132/200\n",
      "Loss : 0.020982143785667887, ACC : 0.895680521597392\n",
      "Epoch 133/200\n",
      "Loss : 0.020956426251682696, ACC : 0.895680521597392\n",
      "Epoch 134/200\n",
      "Loss : 0.021170282082141854, ACC : 0.8842705786471068\n",
      "Epoch 135/200\n",
      "Loss : 0.021100773253670144, ACC : 0.8867155664221679\n",
      "Epoch 136/200\n",
      "Loss : 0.020955527227101717, ACC : 0.8948655256723717\n",
      "Epoch 137/200\n",
      "Loss : 0.020963609898683008, ACC : 0.8973105134474327\n",
      "Epoch 138/200\n",
      "Loss : 0.02097185433348117, ACC : 0.8924205378973105\n",
      "Epoch 139/200\n",
      "Loss : 0.020985263581186558, ACC : 0.895680521597392\n",
      "Epoch 140/200\n",
      "Loss : 0.02104865620557914, ACC : 0.8883455582722086\n",
      "Epoch 141/200\n",
      "Loss : 0.021161020579334187, ACC : 0.8859005704971475\n",
      "Epoch 142/200\n",
      "Loss : 0.020979474838322125, ACC : 0.8924205378973105\n",
      "Epoch 143/200\n",
      "Loss : 0.020947839150899, ACC : 0.8973105134474327\n",
      "Epoch 144/200\n",
      "Loss : 0.020848288998529984, ACC : 0.8973105134474327\n",
      "Epoch 145/200\n",
      "Loss : 0.02099211092585942, ACC : 0.8940505297473512\n",
      "Epoch 146/200\n",
      "Loss : 0.020956137701079625, ACC : 0.8973105134474327\n",
      "Epoch 147/200\n",
      "Loss : 0.02099046847056643, ACC : 0.8981255093724532\n",
      "Epoch 148/200\n",
      "Loss : 0.020823206421604172, ACC : 0.8997555012224939\n",
      "Epoch 149/200\n",
      "Loss : 0.02099993205595133, ACC : 0.8948655256723717\n",
      "Epoch 150/200\n",
      "Loss : 0.02077217930783658, ACC : 0.9005704971475142\n",
      "Epoch 151/200\n",
      "Loss : 0.020957966596981133, ACC : 0.8924205378973105\n",
      "Epoch 152/200\n",
      "Loss : 0.020807858929948877, ACC : 0.8997555012224939\n",
      "Epoch 153/200\n",
      "Loss : 0.02091497382013994, ACC : 0.8973105134474327\n",
      "Epoch 154/200\n",
      "Loss : 0.020682174836899464, ACC : 0.9030154849225754\n",
      "Epoch 155/200\n",
      "Loss : 0.020754929568190448, ACC : 0.902200488997555\n",
      "Epoch 156/200\n",
      "Loss : 0.020908709308823242, ACC : 0.8916055419722901\n",
      "Epoch 157/200\n",
      "Loss : 0.020769910396554164, ACC : 0.9005704971475142\n",
      "Epoch 158/200\n",
      "Loss : 0.020881535177223062, ACC : 0.895680521597392\n",
      "Epoch 159/200\n",
      "Loss : 0.0209942365819687, ACC : 0.8948655256723717\n",
      "Epoch 160/200\n",
      "Loss : 0.020911840180021627, ACC : 0.8973105134474327\n",
      "Epoch 161/200\n",
      "Loss : 0.020993438307211083, ACC : 0.8973105134474327\n",
      "Epoch 162/200\n",
      "Loss : 0.020705670045465596, ACC : 0.9062754686226568\n",
      "Epoch 163/200\n",
      "Loss : 0.020748126089038553, ACC : 0.9038304808475958\n",
      "Epoch 164/200\n",
      "Loss : 0.020705775264422875, ACC : 0.8997555012224939\n",
      "Epoch 165/200\n",
      "Loss : 0.02083135399278238, ACC : 0.8973105134474327\n",
      "Epoch 166/200\n",
      "Loss : 0.020941075893952384, ACC : 0.8973105134474327\n",
      "Epoch 167/200\n",
      "Loss : 0.020771877058366497, ACC : 0.9005704971475142\n",
      "Epoch 168/200\n",
      "Loss : 0.020644246511762474, ACC : 0.9038304808475958\n",
      "Epoch 169/200\n",
      "Loss : 0.0209231368389767, ACC : 0.8989405052974735\n",
      "Epoch 170/200\n",
      "Loss : 0.02077369210966836, ACC : 0.8973105134474327\n",
      "Epoch 171/200\n",
      "Loss : 0.02085612722791689, ACC : 0.8948655256723717\n",
      "Epoch 172/200\n",
      "Loss : 0.020843366441827726, ACC : 0.9013854930725347\n",
      "Epoch 173/200\n",
      "Loss : 0.020841016260316533, ACC : 0.8973105134474327\n",
      "Epoch 174/200\n",
      "Loss : 0.020686950155070088, ACC : 0.9005704971475142\n",
      "Epoch 175/200\n",
      "Loss : 0.020765904060882967, ACC : 0.8989405052974735\n",
      "Epoch 176/200\n",
      "Loss : 0.020773650381559264, ACC : 0.902200488997555\n",
      "Epoch 177/200\n",
      "Loss : 0.02074077941580526, ACC : 0.9046454767726161\n",
      "Epoch 178/200\n",
      "Loss : 0.02088642494408406, ACC : 0.8973105134474327\n",
      "Epoch 179/200\n",
      "Loss : 0.020682684172433668, ACC : 0.902200488997555\n",
      "Epoch 180/200\n",
      "Loss : 0.020874758658607315, ACC : 0.8997555012224939\n",
      "Epoch 181/200\n",
      "Loss : 0.020722720325721797, ACC : 0.9013854930725347\n",
      "Epoch 182/200\n",
      "Loss : 0.020765356203357475, ACC : 0.9013854930725347\n",
      "Epoch 183/200\n",
      "Loss : 0.020588285619880284, ACC : 0.9070904645476773\n",
      "Epoch 184/200\n",
      "Loss : 0.020902851294383053, ACC : 0.9030154849225754\n",
      "Epoch 185/200\n",
      "Loss : 0.020651400186419002, ACC : 0.9062754686226568\n",
      "Epoch 186/200\n",
      "Loss : 0.020599203422580585, ACC : 0.9103504482477588\n",
      "Epoch 187/200\n",
      "Loss : 0.020693460468752364, ACC : 0.9038304808475958\n",
      "Epoch 188/200\n",
      "Loss : 0.020611319487524305, ACC : 0.9062754686226568\n",
      "Epoch 189/200\n",
      "Loss : 0.02053782778633447, ACC : 0.9111654441727791\n",
      "Epoch 190/200\n",
      "Loss : 0.020648797936039236, ACC : 0.9054604726976365\n",
      "Epoch 191/200\n",
      "Loss : 0.020641675108122263, ACC : 0.9070904645476773\n",
      "Epoch 192/200\n",
      "Loss : 0.020638682197144872, ACC : 0.9054604726976365\n",
      "Epoch 193/200\n",
      "Loss : 0.020611996075537695, ACC : 0.9070904645476773\n",
      "Epoch 194/200\n",
      "Loss : 0.020604816169008163, ACC : 0.9046454767726161\n",
      "Epoch 195/200\n",
      "Loss : 0.020620185374825004, ACC : 0.9038304808475958\n",
      "Epoch 196/200\n",
      "Loss : 0.020562156245488895, ACC : 0.9054604726976365\n",
      "Epoch 197/200\n",
      "Loss : 0.02074697825028436, ACC : 0.902200488997555\n",
      "Epoch 198/200\n",
      "Loss : 0.020644165047223526, ACC : 0.9038304808475958\n",
      "Epoch 199/200\n",
      "Loss : 0.020588076347826747, ACC : 0.9070904645476773\n",
      "Epoch 200/200\n",
      "Loss : 0.0205430004688036, ACC : 0.9095354523227384\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(Epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    \n",
    "    print(\"Epoch {}/{}\".format(epoch+1, Epochs))\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _,preds = torch.max(outputs,1)\n",
    "        _,lab = torch.max(labels,1)        \n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, lab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_acc += torch.sum(preds==lab.data)\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_dataset)\n",
    "    epoch_acc = running_acc.double() / len(train_dataset)\n",
    "    loss_list.append(epoch_loss)\n",
    "    acc_list.append(epoch_acc)\n",
    "    \n",
    "    print(\"Loss : {}, ACC : {}\".format(epoch_loss,epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b9172af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.024798665923633795, ACC : 0.7793103456497192\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc= 0\n",
    "pred_list = []\n",
    "label_list = []\n",
    "for data in test_loader:\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "    _,preds = torch.max(outputs,1)\n",
    "    _,lab = torch.max(labels,1)\n",
    "    \n",
    "    loss = criterion(outputs, lab)\n",
    "    \n",
    "    test_loss += loss.item()\n",
    "    test_acc += torch.sum(preds==lab.data)\n",
    "\n",
    "    pred_list.extend([p for p in preds.tolist()])\n",
    "    label_list.extend(lab.tolist())\n",
    "    \n",
    "test_loss = test_loss/len(test_dataset)\n",
    "test_acc = test_acc.float()/len(test_dataset)\n",
    "print(\"Loss : {}, ACC : {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a875a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Radial Velocity'),\n",
       " Text(0, 1.5, 'Transit'),\n",
       " Text(0, 2.5, 'Others')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classes = ['Radial Velocity','Transit', 'Others']\n",
    "\n",
    "cm = confusion_matrix(label_list,pred_list)\n",
    "c = sns.heatmap(cm,annot=True,fmt='g')\n",
    "c.set(ylabel = \"True Label\", xlabel = \"Predict\")\n",
    "c.set_xticklabels(classes)\n",
    "c.set_yticklabels(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
