{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3c735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf454f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_train = pd.read_csv(\"C:/Users/user/.jupyter/주피터 파일/data/planets_train.csv\")\n",
    "planets_train.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "planets_test = pd.read_csv(\"C:/Users/user/.jupyter/주피터 파일/data/planets_test.csv\")\n",
    "planets_test.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b9d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = planets_train.iloc[:, 1:6]\n",
    "train_y = planets_train.iloc[:, 0]\n",
    "\n",
    "test_x = planets_test.iloc[:, 1:6]\n",
    "test_y = planets_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d846f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.where((train_y == 'Radial Velocity') | (train_y == 'Transit'), 'Others')\n",
    "test_y = test_y.where((test_y == 'Radial Velocity') | (test_y == 'Transit'), 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[['orbital_period', 'distance', 'mass']] = np.log(train_x[['orbital_period', 'distance', 'mass']])\n",
    "test_x[['orbital_period', 'distance', 'mass']] = np.log(test_x[['orbital_period', 'distance', 'mass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b8286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.interpolate()\n",
    "test_x = test_x.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2075e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "\n",
    "train_x = RobustScaler().fit_transform(train_x)\n",
    "test_x = RobustScaler().fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438dcb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "x_train, y_train = SMOTE(random_state=0).fit_resample(train_x, train_y)\n",
    "x_test, y_test = SMOTE(random_state=0).fit_resample(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb62cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "y_test = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc2159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = pd.get_dummies(y_train).values\n",
    "y_test_oh = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf3b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout,self.W.T)\n",
    "        self.dw = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        self.x = x\n",
    "        out = np.dot(self.x,self.W) + self.b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999d6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.parameter = {}\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = x.copy()\n",
    "        mask = (x<0)\n",
    "        self.mask = mask\n",
    "        y[mask] = 0 \n",
    "        return y\n",
    "    \n",
    "    def backward(self,dy):\n",
    "        mask=self.mask\n",
    "        dx = dy.copy()\n",
    "        dx[mask] = 0\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9c2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self,lr=0.001, beta1=0.9, beta2=0.99):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        self.iter = 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.m[key] += (1-self.beta1) * (grads[key]-self.m[key])\n",
    "            self.v[key] += (1-self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key])+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2d1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self,dropout_ratio = 0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self,x, train_flag = True):\n",
    "        if train_flag:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0-self.dropout_ratio)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a9fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8\n",
    "class CrossEntropyWithSoftmax() :\n",
    "    \n",
    "    def __init__(self,reduction=True) :\n",
    "        self.p_ = {}\n",
    "        self.T = None\n",
    "        self.Y = None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self,T,X) :\n",
    "        self.T = T\n",
    "        expX = np.exp(X-np.max(X))\n",
    "        Y = expX/(eps + np.sum(expX,axis=1,keepdims=True))\n",
    "        self.Y = Y\n",
    "        loss = T*np.log(Y)\n",
    "        \n",
    "        if self.reduction :\n",
    "            loss = -np.sum(loss)\n",
    "\n",
    "        else :\n",
    "            loss = -np.sum(loss,axis=1)\n",
    "\n",
    "        return (loss, Y)\n",
    "\n",
    "    def backward(self,dY) :\n",
    "        T = self.T; Y = self.Y\n",
    "        \n",
    "        return Y - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "643de164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net():\n",
    "    def __init__(self, input_size, hidden_size_list, output_size,\n",
    "                activation='relu', weight_init_std = 'he', weight_decay_lambda=0,\n",
    "                use_dropout=False, dropout_ration = 0.5):\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "        self.use_dropout = use_dropout\n",
    "        self.weight_decay_lambda = weight_decay_lambda\n",
    "        self.params ={}\n",
    "        \n",
    "        self.__init_weight(weight_init_std)\n",
    "        \n",
    "        activation_layer = {'relu':ReLU}\n",
    "        self.layers = collections.OrderedDict()\n",
    "        \n",
    "        for idx in range(1,self.hidden_layer_num+1):\n",
    "            self.layers['Affine'+str(idx)] = Affine(self.params['W'+str(idx)],\n",
    "                                                   self.params['b'+str(idx)])\n",
    "            \n",
    "            self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\n",
    "            if self.use_dropout:\n",
    "                self.layers['Dropout'+str(idx)] = Dropout(dropout_ration)\n",
    "                \n",
    "        \n",
    "        idx = self.hidden_layer_num+1\n",
    "        self.layers['Affine' + str(idx)] = Affine(self.params['W'+str(idx)],\n",
    "                                                 self.params['b'+str(idx)])\n",
    "        \n",
    "        self.last_layer = CrossEntropyWithSoftmax()\n",
    "        \n",
    "    def __init_weight(self,weight_init_std):\n",
    "        \n",
    "        all_size_list = [self.input_size]+self.hidden_size_list + [self.output_size]\n",
    "        for idx in range(1, len(all_size_list)):\n",
    "            scale = weight_init_std\n",
    "            if str(weight_init_std).lower() in ('relu','he'):\n",
    "                scale = np.sqrt(2.0/all_size_list[idx-1])\n",
    "            elif str(weight_init_std).lower() in ('sigmoid','xavier'):\n",
    "                scale = np.sqrt(1.0/all_size_list[idx-1])\n",
    "            self.params['W'+str(idx)] = scale*np.random.randn(all_size_list[idx-1], all_size_list[idx])\n",
    "            self.params['b'+str(idx)] = np.zeros(all_size_list[idx])\n",
    "            \n",
    "    def predict(self,x,train_flag = False):\n",
    "        for key,layer in self.layers.items():\n",
    "            if \"Dropout\" in key or \"BacthNorm\" in key:\n",
    "                x = layer.forward(x,train_flag)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t,train_flag = False):\n",
    "        y = self.predict(x,train_flag)\n",
    "        weight_decay = 0\n",
    "        \n",
    "        for idx in range(1,self.hidden_layer_num+2):\n",
    "            W = self.params['W'+str(idx)]\n",
    "            weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
    "        temp,_ = self.last_layer.forward(t,y)\n",
    "        return  temp + weight_decay\n",
    "    \n",
    "    def accuracy(self,X,T):\n",
    "        Y = self.predict(X, train_flag = False)\n",
    "#         if T.ndim !=1:\n",
    "#             T = np.argmax(T,axis=1)\n",
    "\n",
    "        _, Y = self.last_layer.forward(T,Y)\n",
    "        Y = np.argmax(Y,axis=1)\n",
    "        T = np.argmax(T,axis=1)\n",
    "        accuracy = np.mean(Y==T)*100\n",
    "        return (Y,accuracy)\n",
    "    \n",
    "\n",
    "\n",
    "    def numerical_gradient(self,X,T):\n",
    "        loss_W = lambda W: self.loss(X,T,train_flag = True)\n",
    "        grads = {}\n",
    "        \n",
    "        for idx in range(1, self.hidden_layer_num+2):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_W, self.params['W'+str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_W, self.params['b'+str(idx)])\n",
    "            \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        self.loss(x,t,train_flag = True)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        grads = {}\n",
    "        for idx in range(1,self.hidden_layer_num +2):\n",
    "            grads['W' + str(idx)] = self.layers['Affine'+str(idx)].dw + self.weight_decay_lambda *self.params['W'+str(idx)]\n",
    "            grads['b' + str(idx)] = self.layers['Affine'+str(idx)].db\n",
    "            \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b202b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net(input_size = 5, hidden_size_list = [64,256],output_size = 3,use_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ec5c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "N = len(x_train)\n",
    "batch_size = 16\n",
    "Epochs = 30\n",
    "iter_num = int(N/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b08ddb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 1th epoch\n",
      "Loss : 15.93706243942397\n",
      "Train acc : 75.57565789473684, Test acc : 52.51361161524503\n",
      "*** 2th epoch\n",
      "Loss : 16.85076552513994\n",
      "Train acc : 66.11842105263158, Test acc : 59.39806412583181\n",
      "*** 3th epoch\n",
      "Loss : 13.41471894538644\n",
      "Train acc : 64.96710526315789, Test acc : 62.90986085904416\n",
      "*** 4th epoch\n",
      "Loss : 11.550320452209576\n",
      "Train acc : 67.59868421052632, Test acc : 65.42649727767696\n",
      "*** 5th epoch\n",
      "Loss : 10.781486351553333\n",
      "Train acc : 69.07894736842105, Test acc : 66.75438596491227\n",
      "*** 6th epoch\n",
      "Loss : 10.285756656395359\n",
      "Train acc : 69.81907894736842, Test acc : 67.50756200846942\n",
      "*** 7th epoch\n",
      "Loss : 9.828620986714693\n",
      "Train acc : 71.38157894736842, Test acc : 68.23956442831216\n",
      "*** 8th epoch\n",
      "Loss : 9.42928964928993\n",
      "Train acc : 72.53289473684211, Test acc : 68.85057471264368\n",
      "*** 9th epoch\n",
      "Loss : 9.051222543088508\n",
      "Train acc : 73.76644736842105, Test acc : 69.31941923774954\n",
      "***10th epoch\n",
      "Loss : 8.716206308913353\n",
      "Train acc : 75.08223684210526, Test acc : 69.66122202056867\n",
      "***11th epoch\n",
      "Loss : 8.388946735013\n",
      "Train acc : 76.15131578947368, Test acc : 70.01814882032666\n",
      "***12th epoch\n",
      "Loss : 8.085673614905467\n",
      "Train acc : 77.05592105263158, Test acc : 70.37507562008466\n",
      "***13th epoch\n",
      "Loss : 7.788589555133379\n",
      "Train acc : 78.70065789473684, Test acc : 70.7289776164549\n",
      "***14th epoch\n",
      "Loss : 7.5025850396056795\n",
      "Train acc : 79.4407894736842, Test acc : 70.93466424682396\n",
      "***15th epoch\n",
      "Loss : 7.240822730387424\n",
      "Train acc : 80.01644736842105, Test acc : 71.15245009074408\n",
      "***16th epoch\n",
      "Loss : 6.966093790611612\n",
      "Train acc : 81.0032894736842, Test acc : 71.42468239564427\n",
      "***17th epoch\n",
      "Loss : 6.7072482200442645\n",
      "Train acc : 81.90789473684211, Test acc : 71.61222020568664\n",
      "***18th epoch\n",
      "Loss : 6.457147206707324\n",
      "Train acc : 83.22368421052632, Test acc : 71.75741076830009\n",
      "***19th epoch\n",
      "Loss : 6.227345040140877\n",
      "Train acc : 83.88157894736842, Test acc : 71.92982456140354\n",
      "***20th epoch\n",
      "Loss : 5.994320102078723\n",
      "Train acc : 84.375, Test acc : 72.24742891712039\n",
      "***21th epoch\n",
      "Loss : 5.799521781045069\n",
      "Train acc : 85.27960526315789, Test acc : 72.47731397459168\n",
      "***22th epoch\n",
      "Loss : 5.590039988187302\n",
      "Train acc : 86.01973684210526, Test acc : 72.77676950998186\n",
      "***23th epoch\n",
      "Loss : 5.385191903742362\n",
      "Train acc : 86.59539473684211, Test acc : 73.0550514216576\n",
      "***24th epoch\n",
      "Loss : 5.186281376882584\n",
      "Train acc : 87.2532894736842, Test acc : 73.09739866908653\n",
      "***25th epoch\n",
      "Loss : 5.011742054179425\n",
      "Train acc : 87.7467105263158, Test acc : 73.3151845130067\n",
      "***26th epoch\n",
      "Loss : 4.815594051571952\n",
      "Train acc : 88.73355263157895, Test acc : 73.39685420447672\n",
      "***27th epoch\n",
      "Loss : 4.653833670259769\n",
      "Train acc : 89.14473684210526, Test acc : 73.46944948578344\n",
      "***28th epoch\n",
      "Loss : 4.487044285648997\n",
      "Train acc : 89.47368421052632, Test acc : 73.53901996370236\n",
      "***29th epoch\n",
      "Loss : 4.33010420650788\n",
      "Train acc : 89.96710526315789, Test acc : 73.68723532970357\n",
      "***30th epoch\n",
      "Loss : 4.186462551224426\n",
      "Train acc : 90.21381578947368, Test acc : 73.59346642468239\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    train_acc_batch = 0.0\n",
    "    test_acc_batch = 0.0\n",
    "    loss_temp = 0.0\n",
    "    for j in range(iter_num):\n",
    "        iter_n = batch_size * j\n",
    "        x_batch = np.array(x_train)[iter_n:(iter_n+batch_size)]\n",
    "        t_batch = np.array(y_train_oh)[iter_n:(iter_n+batch_size)]\n",
    "        \n",
    "        loss_temp += network.loss(x_batch,t_batch)\n",
    "        \n",
    "        grads = network.gradient(x_batch,t_batch)\n",
    "        optimizer.update(network.params, grads)\n",
    "        \n",
    "        _,acc_tr = network.accuracy(x_batch, t_batch)\n",
    "        preds, acc_te = network.accuracy(np.array(x_test),np.array(y_test_oh))\n",
    "        train_acc_batch += acc_tr\n",
    "        test_acc_batch += acc_te\n",
    "        if (epoch == Epochs-1) and(j == iter_num-1):\n",
    "            preds_list.extend(preds)\n",
    "    train_loss = loss_temp / iter_num\n",
    "    train_acc = train_acc_batch / iter_num\n",
    "    test_acc = test_acc_batch / iter_num\n",
    "    loss_list.append(train_loss)\n",
    "    \n",
    "    print(\"***%2dth epoch\"%(epoch+1))\n",
    "    print(\"Loss : {}\".format(train_loss))\n",
    "    print(\"Train acc : {}, Test acc : {}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56e43274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set -> acc: 73.56%\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = network.accuracy(x_test,y_test_oh)\n",
    "\n",
    "print('test set -> acc: %5.2f%%'%(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52cf2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label= np.array(y_test_oh)\n",
    "tl_list=true_label.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ba4f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Radial Velocity'),\n",
       " Text(0, 1.5, 'Transit'),\n",
       " Text(0, 2.5, 'Others')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classes = ['Radial Velocity','Transit', 'Others']\n",
    "\n",
    "cm = confusion_matrix(tl_list,preds_list)\n",
    "c=sns.heatmap(cm,annot=True,fmt='g')\n",
    "c.set(xlabel = \"predict\" , ylabel = \"True label\")\n",
    "c.set_xticklabels(classes,rotation=45)\n",
    "c.set_yticklabels(classes,rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
